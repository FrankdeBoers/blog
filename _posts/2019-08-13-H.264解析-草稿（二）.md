---
title: H.264解析草稿更新中....（二）
tags: Android 音视频
categories: Android
---

本文分为相关概念、压缩方式等方面展开。仍在缓慢更新...

# 一、H.264相关概念

## 1、帧
在H.264中，一帧表示一个视频图片编码后的数据，一帧由一个或多个片组成，一个片由一个或多个宏块组成，一个宏块由16x16的yuv数据组成。

![帧-片-宏块](https://raw.githubusercontent.com/FrankdeBoers/blog/master/static/img/%E5%B8%A7-%E7%89%87-%E5%AE%8F%E5%9D%97.png)

## 2、I、B、P帧
H.264标准中，定义了I帧、B帧、P帧。

**I帧**：帧内编码帧（intra picture）。是完整的一个图像，单独拿出来可以查看。I帧是每个GOP的第一个帧，经过简单地压缩，作为随机访问的参考点。
在Android中，MediaMetadataRetriever.java#getFrameAtTime(0)，会返回一张图片，作为视频的封面、缩略图，在底层的实现中，就是遍历0S之后的数据，
拿到第一个I帧，然后返回这张图片。注：getFrameAtTime(-1)，并不是随机返回一个I帧，而是在视频中寻找，找出最大的（持续时间最长的）有效帧，然后返回它的I帧。

**P帧**：前向预测编码帧（predictive-frame），表示的是这一帧跟之前的I帧（或者P帧）的差别。解码时需要用之前的I帧，叠加上本帧，生成最终的画面。
所以P帧是差别帧，P帧没有完成的画面数据，单独抽出来是无法查看的。

**B帧**：双向预测内差编码帧（双向差别帧、双向预测帧）（bi-directional interpolated prediction frame）。也是差异帧，既考虑源视频序列前面的已编码帧，
也考虑视频序列后面已编码帧，来压缩产生B帧。  要解码B帧，不仅要获取之前的缓存画面，也要解码之后的画面，然后叠加本帧数据得到最终的画面。B帧的压缩率高，但是解码会大量消耗CPU资源。

**注**：
I帧是完整的视频帧，换句话说，客户端只有在获得I帧后才会有完整的视频。如果直接发送，不等I帧，客户端得到的画面会残缺，但是延迟较低。如果等I帧，客户端缓冲时间较长，得到画面会完整，但是延迟至少是一个GOP。视频通话、播放网络视频时，如果出现花屏现象，一般是由于I帧丢失导致的，可以通过等待I帧后展示画面解决。

## 3、GOP
Grop Of Picture，两个I帧之间的视频帧，包括1个I帧+多个P帧+多个B帧。GOP：IBBPBBPBBPBBI。  一般是一段时间内变化不大的视频帧集。在一个GOP内I frame解码不依赖任何的其它帧，p frame解码则依赖前面的I frame或P frame，B frame解码依赖前最近的一个I frame或P frame 及其后最近的一个P frame。

## 4、IDR帧
在编解码中，把第一个I帧叫做IDR帧，方便控制编码和解码流程，所以IDR帧一定是I帧，反之不成立。IDR帧的作用是立即刷新，避免误码的传播，从IDR帧开始，后面的B、P帧不能参考IDR之前的I帧。

I帧不用参考任何帧，但是之后的P、B帧协议参考这个I帧和之前的I帧。

`IDR1` P4 B2 B3 P7 B5 B6 I10 `B8` B9 P13 B11 B12 P16 B14 B15   这里的B8可以跨过I10去参考P7
`IDR1` P4 B2 B3 P7 B5 B6 `IDR8` P11 `B9` B10 P14 B11 B12 B13 B14  这里的B9就只能参照IDR8和P11，不可以参考IDR8前面的帧

IDR帧，是为了解码的同步，当解码器解码到IDR图像时，立即将参考队列清空，将已解码的数据全部输出或者抛弃，重新查找参数集，开始一个新的序列。 这样，
如果前面的序列出现重大错误，在这里也可以获得重新同步的机会。


# 二、H.264的基本结构

H.264从功能划分为两个层次：视频编码层(Video Coding Layer)和网络抽象层（Network Abstraction Layer）。

![H264结构](https://raw.githubusercontent.com/FrankdeBoers/blog/master/static/img/H264%E7%BB%93%E6%9E%84.png)

VCL负责有效地表示视频数据的内容,最终输出编码完的SODB。

NAL负责格式化数据并提供头信息，以让数据在各种信道和存储介质上的传输。NAL层将SODB打包成RBSP然后加上NAL头组成一个NALU单元  我们平时的每帧数据就是一个NAL单元。 

![NAL单元序列](https://raw.githubusercontent.com/FrankdeBoers/blog/master/static/img/NAL%E5%8D%95%E5%85%83%E5%BA%8F%E5%88%97.png)

# 三、H.264的压缩方式
首先，H.264划分宏块的方式：

以下面这张图片为例:

![](https://raw.githubusercontent.com/FrankdeBoers/blog/master/static/img/%E5%9B%BE%E7%89%871.jpeg)

H.264默认使用16x16像素大小的区域作为一个宏块，也可以细分为8x8像素大小。

![](https://raw.githubusercontent.com/FrankdeBoers/blog/master/static/img/%E5%9B%BE%E7%89%872.jpeg)

划分好宏块后，计算宏块的象素值。

![](https://raw.githubusercontent.com/FrankdeBoers/blog/master/static/img/%E5%9B%BE%E7%89%873.jpeg)

以此类推，计算一幅图像中每个宏块的像素值，所有宏块都处理完后如下面的样子。

![](https://raw.githubusercontent.com/FrankdeBoers/blog/master/static/img/%E5%9B%BE%E7%89%874.jpeg)

H264对比较平坦的图像使用 16X16 大小的宏块。但为了更高的压缩率，还可以在 16X16 的宏块上更划分出更小的子块。子块的大小可以是 8X16､ 16X8､ 8X8､ 4X8､ 8X4､ 4X4非常的灵活。

![](https://raw.githubusercontent.com/FrankdeBoers/blog/master/static/img/%E5%9B%BE%E7%89%875.jpeg)

上幅图中，红框内的 16X16 宏块中大部分是蓝色背景，而三只鹰的部分图像被划在了该宏块内，为了更好的处理三只鹰的部分图像，H264就在 16X16 的宏块内又划分出了多个子块。

![](https://raw.githubusercontent.com/FrankdeBoers/blog/master/static/img/%E5%9B%BE%E7%89%876.jpeg)

这样再经过帧内压缩，可以得到更高效的数据。下图是分别使用mpeg-2和H264对上面宏块进行压缩后的结果。其中左半部分为MPEG-2子块划分后压缩的结果，右半部分为H264的子块划压缩后的结果，可以看出H264的划分方法更具优势。

![](https://raw.githubusercontent.com/FrankdeBoers/blog/master/static/img/%E5%9B%BE%E7%89%877.jpeg)


### 帧内预测
```text
对特定的宏块编码时，利用周围的宏块的预测值和实际值的差进行编码。
人眼对图像有一个识别度，对于低频的亮度很敏感，对于高频的亮度不太敏感，
所以基于一些研究，可以将一副图像中，人眼不敏感的数据去除，这样就提出了帧内预测技术。
```
  
 
