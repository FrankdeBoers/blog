---
title: Camera软硬件架构
tags: Android Camera
categories: Android
---

# Camera 硬件架构

本部分主要介绍平台支持的Image Sensor类型，硬件接口以及常见基本概念

## 1，Image Sensor类型

> a)YUV Sensor YUV
> 
> Sensor输出的Data格式为YUV，图像的效果处理使用Sensor内部的ISP，BB端接收YUV格式的data后只进行格式的转换，效果方面不进行处理，由于Sensor内部的ISP处理能力有限，且YUV Sensor的数据量比较大（YUV422的格式1个pixel2个byte），一般Size都比较小，常见的YUV sensor都是5M以下

> b)Raw Sensor 
> 
> Raw Sensor输出的Data格式为Raw，图像的效果处理使用BB端的ISP，BB端接收Raw data后进行一系列的图像处理（OB，Shading，AWB，Gamma，EE，ANR等），效果方面由BB端控制，需要针对不同的模组进行效果调试，Raw sensor是目前的主流，数据量比YUV Sensor小（RAW10 格式的sensor 1个pixel 10个bit）使用平台ISP处理，能支持较大的size


## 2，硬件接口

简单说来，Camera的接口分为并行和串行两种方式，而目前主要支持的串行方式为mipi接口，Parallel接口和mipi接口的介绍可以参考下图

![这里写图片描述](https://img-blog.csdn.net/20180607145120147?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0ZyYWtpZV9Ld29r/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

![这里写图片描述](https://img-blog.csdn.net/20180607145135673?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0ZyYWtpZV9Ld29r/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)
 

## 3，常见基本概念

> **a)三路电压** 
> 
> camera包含的三路电压为模拟电压（VCAMA），数字电压（VCAMD），IO口电压（VCAMIO） 
> **b) I2C信号**
> 
> BB与Sensor端通过I2C来通信（读写寄存器），包括SCL（I2C Clock） SDA（I2C Data）信号 
> **c) mipi几条lane mipi**
> 
> data是成对的差分信号，MIPI_RDN和MIPI_RDP，有几对这样的pin脚，则说明是几条lane，同一颗sensor由于register
> setting不同，输出的信号有可能是2 lane或者4lane等 
> **d) parallel高低八位**
> Parallel接口一般Data有10根pin，分别叫做Data0~Data9，Parallel
> sensor输出的data信号是8根pin时，这八根pin接到的是Data0~Data7还是Data2~Data9，需要配置正确，叫做接到高八位或者低八位，接错了可能产生如下现象

![这里写图片描述](https://img-blog.csdn.net/20180607145151925?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0ZyYWtpZV9Ld29r/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

> **e)Data Format** 
> Sensor输出的数据格式，对于YUV Sensor来说，DataFomat一般有YUYV，YVYU，UYVY等，配置不对可能会导致颜色和亮度错掉，例如下图

![这里写图片描述](https://img-blog.csdn.net/2018060714520796?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0ZyYWtpZV9Ld29r/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)             

> 对于Raw Sensor来说，Data Format就是First Pixel的颜色，分为R，Gr，Gb，B，配置不对会导致颜色错误
> 
> **f)MCLK** 
>
> BB提供给Sensor的外部clock 
> 
> **g)PCLK**
> 
> **h)mipi 信号**
> 
>  mipi信号包括mipi clock和mipi data，该信号是高速信号，用来传输mipi数据包

# Camera软件架构

主要包含三个部分的介绍：

1)Android Camera 架构：Android系统原生架构简要介绍.

2)Android Camera架构: 简要介绍Camera 的架构.

3)Camera data path: 介绍在平台端Camera的数据流.

## 1.下图为Android Camera 架构

![android camera architecture](https://img-blog.csdn.net/20180607144323882?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0ZyYWtpZV9Ld29r/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

**Camera根据Android 架构从上至下可分为**

    1)Applications: 最上层的应用，编译后生成Camera  APK；
    
    2)Application Framework: 主要为Applications提供API;
    
    3)JNI: 使Application Framework和Libraries可交互;
    
    4)Libraries: 包括Camera Framework和Camera Service(camera service和camera client);
    
    5)HAL: 硬件抽象层, 用来链接driver和 Camera Service;
    
    6)Kernel: image sensor driver的实作.
    
其中2)～4)的部分基本为Android原生的架构和code，Camera APK是原生Camera APK应用. 

## 2.下图为Camera从application到kernel层详细的架构.

![Camera Architecture](https://img-blog.csdn.net/20180607144347989?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0ZyYWtpZV9Ld29r/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

1)蓝色部分主要由Java实现(偏向应用层)、黄色为JNI实现(C++，衔接Java层和Native层)， 绿色由C++实现(通常称为Native层)，而枣红色为C实现(Kernel 层).

2) HAL libraries为在HAL层的实现,主要分Camera HAL和Camera Core两大部分.Camera HAL衔接Camera Service并响应它的需求,实现各个feature的scenario; 而Camera Core提供平台一些通用的数据流控制接口.
 

## 3.最后这部分为Camera的数据流简要介绍

![camera数据流](https://img-blog.csdn.net/20180607144432816?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0ZyYWtpZV9Ld29r/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

说明：
1) TG(Timing Generate):从sensor获取数据，并送给ISP处理.

2) Platform Data Processor: 包括平台在后端对图像数据进行resize、rotate、flip、format convert等处理.它可以同时有两个buffer输出.

>    当normal preview时，port1输出给display，port2输出给face detection或者app preview callback。
> 
>    当normal capture时，port1输出大图给jpeg encoder，port2输出小图给回显和thumbnail encode。
> 
>    当video record时，port1输出给display，port2输出给video encoder.
